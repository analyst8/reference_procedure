{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Data\n",
    "\n",
    "Do an initial review of the data\n",
    "    - combine data\n",
    "    - convert format (eg. to dataframe, dictionary, etc.)\n",
    "    - check & change variable type if necessary (eg. int, float, etc.)\n",
    "    - get basic statistics (eg. ave, min, max, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Combine Data\n",
    "People seem to combine the test and train dataset and do the manipulation on that. Then separate it afterwards?\n",
    "<br>Udemy course says not to combine to do manipulation because if use something like frequent category imputation then the test set could be completely different than the train set.\n",
    "\n",
    "I think data may be combined where there is not a sufficiently large test dataset.\n",
    "\n",
    "NEED MORE INFO HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train and test dataset\n",
    "combined_df =  pd.concat(objs=[train_df, test_df], axis=0, sort=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Format\n",
    "\n",
    "Can change the format in order to allow for mathematical operations over the entire dataset. Format options are:\n",
    "    - LIST (square brackets) (eg.['hi',1,[1,2]])\n",
    "    - tuple (round brackets) (eg. ( 'abcd', 786 , 2.23, 'john', 70.2  ) )\n",
    "    - dictionary (curly brackets with colon) (eg. {'name': 'john'}) (d = {'key1':'item1','key2':'item2'})\n",
    "    - pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check format\n",
    "type(df)\n",
    "\n",
    "# change format\n",
    "# You can convert a list,numpy array, or dictionary to a Series\n",
    "my_list = [10,20,30]\n",
    "\n",
    "# convert list to series (can also use pd.Series to convert dictionaries and arrays)\n",
    "pd.Series(data=my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Variable Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting proper variable type:\n",
    "- helps with memory management\n",
    "- determine what values you can assign to it and what you can do to it (including operations you can perform)\n",
    "- helps to select appropriate plots for visualization\n",
    "\n",
    "Python has variable types: \n",
    "    - numbers\n",
    "        - INT (eg. 5, -6) (enables mathematical operations)\n",
    "        - LONG (eg. 51924361L, 0xDEFABCEC)\n",
    "        - FLOAT (eg. 15.20, 32.3+e18) (enables mathematical operations)\n",
    "        - COMPLEX (eg. 9.322e-36j)\n",
    "    - DATETIME (enables date-based attributes and methods)\n",
    "    - CATEGORY (uses less memory and runs fast)\n",
    "    - BOOLEAN (eg. True or False) (enable logical and mathematical operations)\n",
    "    - STRINGS (eg. HelloWorld!) (can use single or double quotes) (quotes inside quotes: \" wrap lot's of quotes\")\n",
    "    \n",
    "Variable can be:\n",
    "- CATEGORICAL - boolean, strings, category, date \n",
    "    - nominal (no order eg. postcode), ordinal (can be meaningful ordered eg. student grade)\n",
    "- NUMERIC - int, long, float, complex \n",
    "    - discrete (always round number eg.# family members), continuous (any value within some range eg. house cost\n",
    "- MIXED - numbers and/ or labels\n",
    "\n",
    "If given in dataset, look at the given description of the column names (OR search the web to determine what the variable means) to determine if the type of variable listed in \"info\" is appropriate or should be changed.\n",
    " Need more info here on when to change and the variable types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DETERMINE variable types of columns with\n",
    "# if not many columns, can use\n",
    "train.dtypes\n",
    "# OR if many columns, use\n",
    "# Get a Series object containing the data type objects of each column of Dataframe.\n",
    "# Index of series is column name.\n",
    "dataTypeSeries = train.dtypes\n",
    "print('Data type of each column of Dataframe :')\n",
    "print(dataTypeSeries.to_string())\n",
    "\n",
    "# OR specific columns\n",
    "type(df['timeStamp'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REVIEW variable values\n",
    "for var in data.columns:\n",
    "    print(var, data[var].unique()[0:20], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a summary of any columns that will be feature engineered (eg. mixed variable columns) AND any columns that will be changed.\n",
    "\n",
    "Also, can do a summary of which columns are what type, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL!\n",
    "# make list of variables  types\n",
    "\n",
    "# numerical: discrete vs continuous\n",
    "discrete = [var for var in data.columns if data[var].dtype!='O' and var!='survived' and data[var].nunique()<10]\n",
    "continuous = [var for var in data.columns if data[var].dtype!='O' and var!='survived' and var not in discrete]\n",
    "\n",
    "# mixed\n",
    "mixed = ['cabin']\n",
    "\n",
    "# categorical\n",
    "categorical = [var for var in data.columns if data[var].dtype=='O' and var not in mixed]\n",
    "\n",
    "print('There are {} discrete variables'.format(len(discrete)))\n",
    "print('There are {} continuous variables'.format(len(continuous)))\n",
    "print('There are {} categorical variables'.format(len(categorical)))\n",
    "print('There are {} mixed variables'.format(len(mixed)))\n",
    "\n",
    "# can list what is in each type of variable\n",
    "# put each of the commands below in separate cell\n",
    "discrete\n",
    "continuous\n",
    "categorical\n",
    "mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF NECESSARY, CHANGE to appropriate format, refer to above notes\n",
    "# Not sure when to change yet? save memory\n",
    "\n",
    "# change datatype where the brackets on left side creates or overwrites existing series\n",
    "dataset['column_name']=dataset.column.astype('data_type')\n",
    "\n",
    "# Each type of integer has a different range of storage capacity\n",
    "#  Type      Capacity\n",
    "#  Int16 -- (-32,768 to +32,767)\n",
    "#  Int32 -- (-2,147,483,648 to +2,147,483,647)\n",
    "#  Int64 -- (-9,223,372,036,854,775,808 to +9,223,372,036,854,775,807)\n",
    "\n",
    "# Cast all columns to int32\n",
    "df.astype('int32').dtypes\n",
    "\n",
    "# Cast all columns to int64\n",
    "ser.astype('int64')\n",
    "\n",
    "# Cast col1 to int32 using a dictionary\n",
    "df.astype({'col1': 'int32'}).dtypes\n",
    "\n",
    "# Cast all columns to category\n",
    "ser.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get Basic Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- look for correlations in features by using metadata\n",
    "- is there a way to rate similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine # rows & columns in train and test dataset\n",
    "# This will help determine what columns may need to be added if train and test set are merged\n",
    "\n",
    "# printing size and shape \n",
    "print(\"Size of train- total number of elements = {}\\nShape of train- rows then columns = {}\".\n",
    "format(train.size, train.shape))\n",
    "print()\n",
    "print(\"Size of features- total number of elements = {}\\nShape of features- rows then columns = {}\".\n",
    "format(features.size, features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head, gives first few rows of data (n= num rows)\n",
    "df.head(n=5)\n",
    "\n",
    "# tail\n",
    "df.tail()\n",
    "\n",
    "# describe gives, count, mean, std, etc.\n",
    "df.describe()\n",
    "\n",
    "# info gives variables, types, nulls, etc.\n",
    "# change the type of column is needed\n",
    "df.info()\n",
    "\n",
    "# We can grab information and arrays out of this dictionary to set up our data frame and understanding of the features\n",
    "print(cancer['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a note of any observations from above summary statistics\n",
    "- are there any inappropriate values\n",
    "- outliers (too high and/ or low)\n",
    "- list more here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Possible Additional Summary Statistics\n",
    "\n",
    "May have some questions that want to have answered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some datasets have a description\n",
    "print(boston_dataset.DESCR)\n",
    "\n",
    "# get mean of a column that is grouped\n",
    "df.groupby('Company').mean()\n",
    "\n",
    "# can use: .std(), .min(), .max(), .count(), .transpose()\n",
    "\n",
    "# What is the max Close price for each bank's stock throughout the time period?\n",
    "# xs() function is used to get cross-section from the Series/DataFrame\n",
    "# this dataframe had bank stock header then a stock info ticker\n",
    "bank_stocks.xs(key='Close',axis=1,level='Stock Info').max()\n",
    "\n",
    "# What is the highest amount of OvertimePay in the dataset ?\n",
    "sal['OvertimePay'].max(axis=0)\n",
    "\n",
    "# What is the job title of JOSEPH DRISCOLL ?\n",
    "sal[sal['EmployeeName']=='JOSEPH DRISCOLL']['JobTitle']\n",
    "\n",
    "# What is the name of highest paid person (including benefits)?\n",
    "sal[sal['TotalPayBenefits']== sal['TotalPayBenefits'].max()] #['EmployeeName']\n",
    "\n",
    "# mean for each year\n",
    "s= sal.groupby('Year')\n",
    "s.mean()['BasePay']\n",
    "\n",
    "# What are the top 5 most common jobs?\n",
    "sal['JobTitle'].value_counts().head(5)\n",
    "\n",
    "# How many people have the word Chief in their job title? \n",
    "def chief_string(title):\n",
    "    if 'chief' in title.lower():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# % change for each bank\n",
    "for tick in tickers:\n",
    "    returns[tick+' Return'] = bank_stocks[tick]['Close'].pct_change()\n",
    "returns.head()\n",
    "\n",
    "- print(\"Dates go from day\", max(train['Date']), \"to day\", min(train['Date']), \", a total of\", train['Date'].nunique(), \"days\")\n",
    "- print(\"Countries with Province/State informed: \", train.loc[train['Province_State']!='None']['Country_Region'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
